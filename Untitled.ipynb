{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f5668bbc-0db1-4f0d-a6f4-4bfb8a1e0237",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Probabilistic.Parameter import ProbabilisticParameters\n",
    "nSamples = 50\n",
    "\n",
    "pps = ProbabilisticParameters.ReadCsv('Probabilistic/1.csv')\n",
    "samples = pps.GenerateSamplesAsDF(nSamples,)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from Probabilistic.EnergyPredictions import EnergyPrediction, ProbabilisticEnergyPrediction\n",
    "\n",
    "pEnergies = []\n",
    "for i in range(nSamples):\n",
    "    data = pd.read_csv(f'Test/{i}.csv', index_col=0)\n",
    "    data = data[[c for c in data.columns if 'Energy' in c]]\n",
    "    pEnergies += [EnergyPrediction(None, data)]\n",
    "\n",
    "d = ProbabilisticEnergyPrediction(None, pEnergies)\n",
    "\n",
    "from MLModels.Generator import Generator, TrainRegressor, tf\n",
    "from MLModels.MLModel import GetScalingLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5e5b7c-7322-4508-8717-1271641c2f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [\"NN\", \"RC\", \"LR\",]\n",
    "N1 = [50, 100, 200]\n",
    "N2 = [0,]\n",
    "REG = [1e-03, 1e-05, 1e-07]\n",
    "LR = [1e-03, 1e-04, 1e-05]\n",
    "\n",
    "nn = [[nn1, nn2] for nn1 in N1 for nn2 in N2]\n",
    "hyperparametersSet = pd.DataFrame([[n, r, l,] \n",
    "                                    for n in nn\n",
    "                                    for r in REG\n",
    "                                    for l in LR\n",
    "                                ], columns = col).sample(n=8,)\n",
    "                                \n",
    "# TrainRegressor(hyperparameters, samples, d.Values['Total'], f'Test/MLModel/Regressor')\n",
    "m = Generator(10, len(samples.columns), f'Test/MLModel/Generator')\n",
    "m.TuneHyperparameters(hyperparameters, f'Test/MLModel/Regressor.h5', [[5.849e+03, 5.635e+03, 3.422e+03, 1.165e+03, 966.3, 754.7, 1.039e+03, 1.256e+03, 697.4, 961.0, 2.891e+03, 4.607e+03]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5a7db258-116b-4d5d-8840-7c4f911f2377",
   "metadata": {},
   "outputs": [],
   "source": [
    "NumInputs = 25\n",
    "NumOutputs = len(samples.columns)\n",
    "FilePath = f'Test/MLModel/Generator'\n",
    "\n",
    "revScalingX = GetScalingLayer(samples, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "16407b9b-27c8-408f-9e58-011feea43eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [\"NN\", \"RC\", \"LR\",]\n",
    "N1 = [50, 100, 200]\n",
    "N2 = [0,]\n",
    "REG = [1e-03, 1e-05, 1e-07]\n",
    "LR = [1e-03, 1e-04, 1e-05]\n",
    "\n",
    "nn = [[nn1, nn2] for nn1 in N1 for nn2 in N2]\n",
    "\n",
    "hyperparametersSet = pd.DataFrame([[n, r, l,] \n",
    "                                    for n in nn\n",
    "                                    for r in REG\n",
    "                                    for l in LR\n",
    "                                ], columns = col).sample(n=8,)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.InputLayer(input_shape = (NumInputs, )))\n",
    "\n",
    "appendModel = tf.keras.models.load_model(f'Test/MLModel/Regressor.h5')\n",
    "appendModel.trainable = False\n",
    "\n",
    "hyperparameters = hyperparametersSet.iloc[0]\n",
    "for nn in [n for n in hyperparameters['NN'] if n>0]:\n",
    "    model.add( tf.keras.layers.Dense(nn, \n",
    "                                   activation=tf.keras.activations.relu, \n",
    "                                   kernel_regularizer=tf.keras.regularizers.L2(hyperparameters['RC'])) )\n",
    "\n",
    "model.add(tf.keras.layers.Dense(NumOutputs))\n",
    "model.add(revScalingX)\n",
    "\n",
    "Generator = model\n",
    "outputs = appendModel(Generator.output)\n",
    "Model = tf.keras.Model(inputs=model.inputs, outputs=outputs)\n",
    "Model.compile(loss=tf.keras.losses.mean_squared_error, optimizer=tf.keras.optimizers.Adam(learning_rate=hyperparameters['LR']),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ff5bc047-a987-4bec-89b1-b5cd0aa2235c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(None, 25)]              0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 50)                1300      \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 10)                510       \n",
      "                                                                 \n",
      " rescaling (Rescaling)       (None, 10)                0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 12)                4612      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,422\n",
      "Trainable params: 1,810\n",
      "Non-trainable params: 4,612\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "786f694f-2dfc-449f-ad1e-c9aeb02c5c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tf.function\n",
    "def __trainStep( actual):\n",
    "    noise = tf.random.normal([len(actual), NumInputs])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape:\n",
    "        predictions = Model(noise, training=True)\n",
    "        gen_loss = tf.keras.losses.mean_squared_error(actual, predictions)\n",
    "        gradients_of_generator = gen_tape.gradient(gen_loss, Model.trainable_variables)\n",
    "        __optimiser.apply_gradients(zip(gradients_of_generator, Model.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a22649c4-2e5d-4be5-bff0-bfa6f3fd5e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(1000):\n",
    "    __trainStep([[5.491, 5.252, 3.128, 1.005, 0.9244, 0.7887, 1.129, 1.331, 0.7129, 0.8923, 2.663, 4.273]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "492ab764-5b3d-4201-acfc-ee10f8662c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u-value:Roof 0.18141706548631192 0.1859008103609085\n",
      "u-value:WallExternal 0.14094083681702613 0.14708734564483167\n",
      "u-value:FloorGround:Office-0-0.0.FloorGround 0.1754997383803129 0.18138396851718425\n",
      "u-value:FloorGround 0.13278868980705738 0.13860541209578514\n",
      "u-value:Window 0.7985418125987053 0.8045815587043762\n",
      "g-value:Window 0.5367220968008042 0.5439827799797058\n",
      "Internal Mass:Office 25.582173824310303 26.145080947875975\n",
      "Permeability 5.889625692367554 5.905472826957703\n",
      "Occupants:Office 21.4496958732605 22.36812644004822\n",
      "Boiler Efficiency 0.7699208080768585 0.7812154933810234\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "dfs = pd.DataFrame(columns=samples.columns)\n",
    "for i in range(50):\n",
    "    ar = Generator(tf.random.uniform([100, NumInputs], seed=i), training=False).numpy().mean(axis=0)\n",
    "    dfs.loc[i] = ar\n",
    "\n",
    "for p in dfs.columns:\n",
    "    print (p, np.percentile(dfs[p], 2.5), np.percentile(dfs[p], 97.5))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "99eb8ff8-1569-48b5-b82c-b2e109295831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.2455645, 1.6918461, 2.2404702, 2.4851096, 3.8193831, 2.334606 ,\n",
       "       3.5197673, 2.9757414, 2.8351212, 2.1819963, 2.73632  , 4.0070453,\n",
       "       3.601113 , 2.579692 , 2.9339209, 2.155013 , 2.6435232, 2.403153 ,\n",
       "       1.5203832, 3.5401192, 2.9283886, 2.6901894, 3.0541487, 3.1554236,\n",
       "       2.8799238, 3.5832815, 2.1038098, 3.5001998, 2.3492327, 2.5301795,\n",
       "       2.5007796, 3.2376742, 1.5464443, 1.8671043, 2.6198986, 2.5063457,\n",
       "       2.889379 , 4.143587 , 3.5045745, 3.444314 , 2.8071945, 3.8895793,\n",
       "       2.9452894, 2.8451028, 3.2274606, 3.0300903, 1.3250508, 2.5112891,\n",
       "       2.0255547, 1.896987 , 2.7032123, 1.8941009, 2.7510288, 1.516119 ,\n",
       "       2.9723623, 2.7425125, 3.8510566, 1.8582423, 2.7949233, 1.6932172,\n",
       "       2.3192368, 2.490482 , 1.72297  , 3.3101394, 2.9246464, 2.5891528,\n",
       "       2.4907725, 2.872213 , 2.2016532, 2.372326 , 2.9932604, 2.153932 ,\n",
       "       2.750996 , 3.5894992, 2.9271836, 2.2000806, 2.4568422, 2.4346242,\n",
       "       2.8061671, 1.673446 , 2.9477887, 2.2909124, 2.9971824, 1.9726906,\n",
       "       2.8821597, 2.109284 , 2.1812315, 2.19516  , 3.4207516, 3.4708698,\n",
       "       2.791214 , 2.657055 , 3.6861897, 1.229902 , 2.1398063, 3.3921125,\n",
       "       1.4643984, 2.2287834, 2.4513798, 3.3813944], dtype=float32)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.losses.mean_squared_error([[5.491, 5.252, 3.128, 1.005, 0.9244, 0.7887, 1.129, 1.331, 0.7129, 0.8923, 2.663, 4.273]], Model(tf.random.uniform([100, NumInputs], seed=i), training=False)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c4658ed7-44da-4a51-8252-10477be76a5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "randint() takes at least 1 positional argument (0 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [133], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint()\n",
      "File \u001b[0;32mmtrand.pyx:646\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: randint() takes at least 1 positional argument (0 given)"
     ]
    }
   ],
   "source": [
    "np.random.randint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d58e0f-48d4-4210-8d18-13308cebedee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
